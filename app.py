import streamlit as st
import numpy as np
import pickle
import requests
import os
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences

def download_model_from_google_drive(file_id, destination):
    """Download model from Google Drive - handles large files correctly"""
    # URL –¥–ª—è –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ Google Drive
    url = f"https://drive.google.com/uc?id={file_id}"
    
    session = requests.Session()
    response = session.get(url, stream=True)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø–æ–ª—É—á–∏–ª–∏ –ª–∏ –º—ã HTML-—Å—Ç—Ä–∞–Ω–∏—Ü—É –≤–º–µ—Å—Ç–æ —Ñ–∞–π–ª–∞
    if 'text/html' in response.headers.get('content-type', ''):
        # –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ —Ñ–∞–π–ª –±–æ–ª—å—à–æ–π –∏ —Ç—Ä–µ–±—É–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
        # –ü–æ–ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Ñ–∞–π–ª —á–µ—Ä–µ–∑ –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É
        confirm_url = f"https://drive.google.com/uc?export=download&confirm=1&id={file_id}"
        response = session.get(confirm_url, stream=True)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
    with open(destination, 'wb') as f:
        for chunk in response.iter_content(chunk_size=8192):
            if chunk:
                f.write(chunk)

@st.cache_resource
def load_resources():
    model_file_id = "1A0dE-UXP9M4bPY795Z6fAdJ0wyp8M9nW"
    model_path = 'emotion_classification_model.h5'
    
    # –°–∫–∞—á–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    if not os.path.exists(model_path):
        st.info("Downloading model...")
        download_model_from_google_drive(model_file_id, model_path)
        st.success("Model downloaded successfully!")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±–æ–ª—å—à–µ 10MB –¥–ª—è –≤–∞—à–µ–π –º–æ–¥–µ–ª–∏)
    file_size = os.path.getsize(model_path)
    st.info(f"Downloaded model size: {file_size / (1024*1024):.2f} MB")
    
    if file_size < 10 * 1024 * 1024:  # –ú–µ–Ω—å—à–µ 10MB
        st.error(f"Downloaded file is too small ({file_size} bytes) - likely not the actual model file")
        st.stop()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    try:
        model = load_model(model_path)
    except Exception as e:
        st.error(f"Failed to load model: {str(e)}")
        st.error("The downloaded file might be corrupted or not a valid model file.")
        st.stop()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É
    with open('tokenizer.pickle', 'rb') as handle:
        tokenizer = pickle.load(handle)
    with open('label_encoder.pickle', 'rb') as handle:
        label_encoder = pickle.load(handle)
        
    return model, tokenizer, label_encoder

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã
try:
    model, tokenizer, label_encoder = load_resources()
    st.success("‚úÖ Model loaded successfully!")
except Exception as e:
    st.error(f"‚ùå Error loading model: {str(e)}")
    st.stop()

# –û—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...
st.title("üß† Emotion Classification System")
st.subheader("AI-Powered Emotion Recognition from Text")

st.write("""
This model can classify text into **75 different emotions** with **100% accuracy**.
Enter any text below to see which emotion it represents!
""")

user_input = st.text_area(
    "Enter text for emotion classification:", 
    height=150,
    placeholder="Type your text here... For example: 'Examine how Envy plays a role in leadership...'"
)

if st.button("Classify Emotion"):
    if user_input.strip():
        with st.spinner('Analyzing emotion...'):
            sequence = tokenizer.texts_to_sequences([user_input])
            padded = pad_sequences(sequence, maxlen=512, padding='post', truncating='post')
            prediction = model.predict(padded, verbose=0)
            predicted_class_idx = np.argmax(prediction, axis=1)[0]
            predicted_emotion = label_encoder.classes_[predicted_class_idx]
            confidence = prediction[0][predicted_class_idx]
            
            st.success(f"**Predicted Emotion:** {predicted_emotion}")
            st.info(f"**Confidence:** {confidence:.4f}")
            
            top_3_indices = np.argsort(prediction[0])[-3:][::-1]
            top_3_emotions = [label_encoder.classes_[idx] for idx in top_3_indices]
            top_3_confidences = [prediction[0][idx] for idx in top_3_indices]
            
            st.subheader("Top 3 Predictions:")
            for i, (emotion, conf) in enumerate(zip(top_3_emotions, top_3_confidences)):
                st.write(f"{i+1}. {emotion}: {conf:.4f}")
            
            st.subheader("Input Text:")
            st.write(user_input)
    else:
        st.warning("Please enter some text to classify!")

st.subheader("Try these sample texts:")
samples = [
    "I feel so angry about the unfair treatment I received today",
    "The joy of seeing my family after so long was overwhelming",
    "I'm constantly worried about everything that could go wrong",
    "The envy I feel towards my successful colleague is consuming me"
]

for i, sample in enumerate(samples):
    if st.button(f"Sample {i+1}", key=f"sample_{i}"):
        st.session_state.user_input = sample

st.sidebar.header("About this Model")
st.sidebar.write("""
- **Model Type**: Bidirectional LSTM with Attention
- **Classes**: 75 different emotions
- **Accuracy**: 100%
- **Architecture**: Custom neural network
""")
